{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# File management\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Linear algebra and dataframes\n",
    "import numpy as np  \n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "from openslide import OpenSlide, lowlevel \n",
    "from shapely.geometry import Polygon\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageDraw\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000000\n",
    "\n",
    "# File extensions\n",
    "import h5py\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Tools\n",
    "import staintools\n",
    "from dgl.data.utils import save_graphs\n",
    "from histocartography.visualization import OverlayGraphVisualization\n",
    "from histocartography.preprocessing import (  \n",
    "    GaussianTissueMask,                 # extract tissue mask   \n",
    "    ColorMergedSuperpixelExtractor,     # superpixel extractor 1\n",
    "    SLICSuperpixelExtractor,            # superpixel extractor 2\n",
    "    AugmentedDeepFeatureExtractor,      # feature extractor\n",
    "    RAGGraphBuilder,                    # graph builder\n",
    "    )\n",
    "\n",
    "from time import sleep\n",
    "from skimage.segmentation import morphological_chan_vese, morphological_geodesic_active_contour, mark_boundaries\n",
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "\n",
    "# size of region : cols, rows \n",
    "def create_image_patches(img, num_rows, num_columns):\n",
    "    \"\"\"\n",
    "    Partition an image into multiple patches of approximately equal size.\n",
    "    The patch size is based on the desired number of rows and columns.\n",
    "    Returns a list of image patches, in row-major order.\n",
    "    \"\"\"\n",
    "\n",
    "    patch_list = []\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "    w, h = width // num_columns, height // num_rows # // is similar to the floor function\n",
    "    #print(w,h)\n",
    "    \n",
    "    for y in range(0, h*num_rows, num_rows): \n",
    "        y_end = min(y + num_rows, height)\n",
    "        for x in range(0, w*num_columns, num_columns):\n",
    "            x_end = min(x + num_columns, width)\n",
    "            patch = img[y:y_end, x:x_end]\n",
    "            patch_list.append(patch)\n",
    "\n",
    "    return patch_list\n",
    "\n",
    "def normalize_image(image, ref, method, standartize_brightness):\n",
    "    if standartize_brightness:\n",
    "        image = staintools.LuminosityStandardizer.standardize(image)\n",
    "        ref = staintools.LuminosityStandardizer.standardize(ref)\n",
    "            \n",
    "    if method == 'reinhard':\n",
    "        normalizer = staintools.ReinhardColorNormalizer()\n",
    "    if method == 'vahadane':\n",
    "        normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "    if method == 'macenko':\n",
    "        normalizer = staintools.StainNormalizer(method='macenko')\n",
    "            \n",
    "    normalizer.fit(ref)\n",
    "    norm_img = normalizer.transform(image)\n",
    "        \n",
    "    return norm_img \n",
    "\n",
    "def save_superpixel_map(\n",
    "        maps: np.ndarray,\n",
    "        path: Path\n",
    "):\n",
    "    output_key = \"default_key\"\n",
    "\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        if not isinstance(maps, tuple):\n",
    "            maps = tuple([maps])\n",
    "\n",
    "        for i, output in enumerate(maps):\n",
    "            f.create_dataset(\n",
    "                f\"{output_key}_{i}\",\n",
    "                data=output,\n",
    "                compression=\"gzip\",\n",
    "                compression_opts=9,\n",
    "            )\n",
    "\n",
    "\n",
    "def count_patches(patches_paths: list):\n",
    "    nb_pos = 0\n",
    "    nb_neg = 0\n",
    "    for patch in patches_paths:\n",
    "        if 'bg_' in patch:\n",
    "            nb_neg += 1\n",
    "        elif 'patch_' in patch:\n",
    "            nb_pos += 1\n",
    "        else : \n",
    "            print(f\"{patch.split('/')[-1].split('.')[0]} is corrupted\")\n",
    "            break\n",
    "    nb_total = nb_neg + nb_pos\n",
    "    return nb_total, nb_neg, nb_pos\n",
    "\n",
    "def save_superpixel_map(\n",
    "        maps: np.ndarray,\n",
    "        path: Path\n",
    "):\n",
    "    output_key = \"default_key\"\n",
    "\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        if not isinstance(maps, tuple):\n",
    "            maps = tuple([maps])\n",
    "\n",
    "        for i, output in enumerate(maps):\n",
    "            f.create_dataset(\n",
    "                f\"{output_key}_{i}\",\n",
    "                data=output,\n",
    "                compression=\"gzip\",\n",
    "                compression_opts=9,\n",
    "            )\n",
    "\n",
    "def get_properties(array):\n",
    "    values = np.unique(array) \n",
    "    properties = measure.regionprops(array+1)\n",
    "    areas = np.array([prop.area for prop in properties])\n",
    "    solidity = np.array([prop.solidity for prop in properties])\n",
    "    eccentricity = np.array([prop.eccentricity for prop in properties])\n",
    "    return values, areas, solidity, eccentricity\n",
    "\n",
    "def swapping(arr):\n",
    "    value, count = np.unique(arr, return_counts=True)\n",
    "    if count[0] < count[1]:\n",
    "        print('Segmentation : swapping 0s and 1s')\n",
    "        arr = np.where((arr==0)|(arr==1), arr^1, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading low level and the region using OpenSlide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDE_ID = 0 # select the slide\n",
    "PATCH_SIZE = 512 # select patch size\n",
    "TASK = 'tangles' # select'plaques\" or 'tangles'\n",
    "SLIDE_DIM_LVL = 0 # select the magnification level\n",
    "\n",
    "main_path = f'/localdrive10TB/users/pablo.mas/datasets/'\n",
    "\n",
    "if TASK == 'plaques':\n",
    "    slides_path = os.path.join(main_path, f'{TASK}/stratifiad/AT8_wsi/')\n",
    "    labels_path = os.path.join(main_path, f'{TASK}/stratifiad/AT8_XML_annotations/')\n",
    "elif TASK == 'tangles':\n",
    "    slides_path = os.path.join(main_path, f'{TASK}/stratifiad/set1_slides/')\n",
    "    labels_path = os.path.join(main_path, f'{TASK}/stratifiad/set1_annotations/')\n",
    "elif TASK == 'tangles2':\n",
    "    slides_path = os.path.join(main_path, f'{TASK}/stratifiad/Set 2 Tangles virtual slides/')\n",
    "    labels_path = os.path.join(main_path, f'{TASK}/stratifiad/Set2 Tangles XML annotations/')\n",
    "else: \n",
    "    print(\"ERROR - Please use a valid task ('plaques' or 'tangles')\")\n",
    "\n",
    "slides = sorted(glob.glob(os.path.join(slides_path,'*.ndpi')))\n",
    "annotations = sorted(glob.glob(os.path.join(labels_path,'*.xml')))\n",
    "\n",
    "for i, slide_path in enumerate(slides):\n",
    "    name = slide_path.split('/')[-1].split('.ndpi')[0]\n",
    "    print(f'{i} : {name}')\n",
    "\n",
    "name = slides[SLIDE_ID].split('/')[-1].split('.ndpi')[0]\n",
    "\n",
    "remove_patches = False # for now it is used for WSI 11\n",
    "slide_name = slides[SLIDE_ID]\n",
    "label_name = annotations[SLIDE_ID]\n",
    "\n",
    "assert slide_name.split('/')[-1].split('.')[0] == label_name.split('/')[-1].split('.')[0], 'Error, slide and label do not match'\n",
    "\n",
    "# Opening the slide image\n",
    "slide = lowlevel.open(slide_name)\n",
    "keys = lowlevel.get_property_names(slide)\n",
    "val = lowlevel.get_property_value(slide,keys[-1])\n",
    "\n",
    "# This are important values for nm -> pixel conversion\n",
    "offsetX = int(lowlevel.get_property_value(slide, 'hamamatsu.XOffsetFromSlideCentre')) # THIS IS IN NANOMETERS!\n",
    "offsetY = int(lowlevel.get_property_value(slide, 'hamamatsu.YOffsetFromSlideCentre')) # THIS IS IN NANOMETERS!\n",
    "\n",
    "resX = float(lowlevel.get_property_value(slide, 'openslide.mpp-x')) # THIS IS IN MICRONS/PIXEL FOR LVL 0!\n",
    "resY = float(lowlevel.get_property_value(slide, 'openslide.mpp-y')) # THIS IS IN MICRONS/PIXEL FOR LVL 0!\n",
    "\n",
    "slide = OpenSlide(slide_name)\n",
    "\n",
    "# Getting slide level dimentions\n",
    "slide_levels = slide.level_dimensions\n",
    "\n",
    "# Printing important information about the current slide\n",
    "print(\"\\n [INFO] The slide have \", len(slide_levels), \" magnification levels:\")\n",
    "for i in range(len(slide_levels)):\n",
    "    print(f\"   Level {i} (mag x{40/2**i}) with dimensions (in pixels) : {slide_levels[i]}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting coordinates from XML and conversion to pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "From nano/micro meters to pixel language :) \n",
    "Larger value is X axis (-->)\n",
    "'''\n",
    "dimsSlide = np.array(slide_levels[0])*[resX,resY] # this is in micrometers :)\n",
    "centerPx_X, centerPx_Y = np.array(slide_levels[0])/2\n",
    "_, factor = np.array(slide_levels[0])/np.array(slide_levels[SLIDE_DIM_LVL])\n",
    "\n",
    "sizeX, sizeY = np.array(slide_levels[0])/factor\n",
    "\n",
    "# Loading the slide annotations from XML file\n",
    "tree = ET.parse(label_name)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Preparing the annotation container\n",
    "labels = []\n",
    "\n",
    "# Getting the annotaiton coordinates from the XML file\n",
    "for boxes in root:\n",
    "    for obejcts in boxes:\n",
    "        type_object = int(obejcts.attrib['Type'])\n",
    "        for vertices in obejcts:\n",
    "            temp_obj = []\n",
    "            for vertex in vertices:\n",
    "                y_mm = float(vertex.attrib['Y']) # this is in milimeters!\n",
    "                x_mm = float(vertex.attrib['X']) # this is in milimeters!\n",
    "                y_p_offset = (y_mm)*1000 - (abs(offsetY)/1000) # this is in micrometers!\n",
    "                x_p_offset = (x_mm)*1000 - (abs(offsetX)/1000) # this is in micrometers!\n",
    "                y_newCenter = y_p_offset + int(centerPx_Y)*resY # this is in micrometers!\n",
    "                x_newCenter = x_p_offset + int(centerPx_X)*resX # this is in micrometers!\n",
    "                y = (y_newCenter/resY)/factor # pixels \n",
    "                x = (x_newCenter/resX)/factor # pixels\n",
    "\n",
    "                ''' Flip '''\n",
    "                y = abs(sizeY - y)\n",
    "                #x = sizeX - x\n",
    "\n",
    "                temp_obj.append([round(x), round(y)])\n",
    "            labels.append([type_object, np.array(temp_obj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thm = slide.read_region((0, 0), SLIDE_DIM_LVL, slide_levels[SLIDE_DIM_LVL])\n",
    "\n",
    "# print(\"\\n[INFO] The whole-slide image with the gray matter annotation ( dim level\", SLIDE_DIM_LVL, \")\")\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.imshow(thm)\n",
    "# plt.plot(labels[0][1][:, 0], labels[0][1][:, 1])\n",
    "# for obj, coordinates in labels:\n",
    "#     plt.plot(coordinates[:, 0], coordinates[:, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate patches & masks: ROI-guided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mask for the WSI\n",
    "mask_ROI = Image.new('L', (int(sizeX), int(sizeY)), 0)\n",
    "mask_obj = Image.new('L', (int(sizeX), int(sizeY)), 0)\n",
    "\n",
    "coords_list = []\n",
    "coords_region_lst = []\n",
    "for obj, coordinates in labels:\n",
    "    if obj == 1: # this are the annotations by Lev.\n",
    "        coordinates2list = coordinates.tolist()\n",
    "        tuples = [tuple(x) for x in coordinates2list]\n",
    "        ImageDraw.Draw(mask_ROI).polygon(tuples, outline=1, fill=1)\n",
    "\n",
    "        polygon_patch = Polygon(coordinates)\n",
    "        coords_region_lst.append(list(polygon_patch.bounds))\n",
    "        # size = (int(coords_region[2]-coords_region[0])+1, int(coords_region[3]-coords_region[1])+1)\n",
    "  \n",
    "    if obj == 2:\n",
    "        coordinates2list = coordinates.tolist()\n",
    "        tuples = [tuple(x) for x in coordinates2list]\n",
    "        ImageDraw.Draw(mask_obj).polygon(tuples, outline=1, fill=1)\n",
    "        \n",
    "        polygon_obj = Polygon(coordinates)\n",
    "        coords_obj = list(polygon_obj.bounds)\n",
    "        coords_list.append(coords_obj)\n",
    "\n",
    "coords_region = []\n",
    "size = []\n",
    "for c in coords_region_lst:\n",
    "    coords_region.append(c) \n",
    "    size.append((int(c[2]-c[0])+1, int(c[3]-c[1])+1))\n",
    "print(coords_region)\n",
    "print(size)\n",
    "\n",
    "mask_ROI_WSI = mask_ROI.point(lambda i: i * 255)\n",
    "mask_obj_WSI = mask_obj.point(lambda i: i * 255)\n",
    "\n",
    "'''\n",
    "# Save and plot just to check if it is working properly\n",
    "mask_ROI_WSI.point(lambda i: i * 255).save('./name.png')\n",
    "mask_obj_WSI.point(lambda i: i * 255).save('./name2.png')\n",
    "'''\n",
    "# plt.figure()\n",
    "# plt.imshow(mask_ROI_WSI, cmap = \"gray\")\n",
    "# #plt.xlim((coords_region[0], coords_region[2]))\n",
    "# #plt.ylim((coords_region[3], coords_region[1]))\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(mask_obj_WSI, cmap = \"gray\")\n",
    "# #plt.xlim((coords_region[0], coords_region[2]))\n",
    "# #plt.ylim((coords_region[3], coords_region[1]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code creates the region and its corresponding patches for the 4 corners of data augmentation.\n",
    "'''\n",
    "\n",
    "patchSize = [PATCH_SIZE, PATCH_SIZE] # [cols, rows]\n",
    "save_path = os.path.join(main_path, f\"{TASK}/{PATCH_SIZE}\", slide_name.split('/')[-1].split('.ndpi')[0])\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(save_path, \"patches\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_path, \"masks\"), exist_ok=True)\n",
    "\n",
    "# mask_WSI: has all the masks for the annotations and is the same size as the WSI.\n",
    "# slide: is the original WSI in the level selected. It is not loaded into RAM yet.\n",
    "# labels: annotations from XML.\n",
    "# coords_list: list of coordinates of annotated objects.\n",
    "\n",
    "k = 0\n",
    "for coords in tqdm(coords_list): \n",
    "    coords[0] = int(math.floor(coords[0]))\n",
    "    coords[1] = int(math.floor(coords[1]))\n",
    "    coords[2] = int(math.ceil(coords[2]))\n",
    "    coords[3] = int(math.ceil(coords[3]))\n",
    "\n",
    "    size_obj = [coords[2]-coords[0]+1, coords[3]-coords[1]+1]\n",
    "    new_region_size = np.array(patchSize) - np.array(size_obj)        \n",
    "\n",
    "    new_coords = (coords[0]-new_region_size[0]/2, coords[1]-new_region_size[1]/2, coords[2]+new_region_size[0]/2, coords[3]+new_region_size[1]/2)  \n",
    "    new_region_obj = slide.read_region((int(new_coords[0]*factor), int(new_coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))      \n",
    "    # new_region_obj = slide.read_region((int(new_coords[0]*factor), int(new_coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))\n",
    "    new_mask_obj = mask_obj_WSI.crop((int(new_coords[0]),int(new_coords[1]),int(new_coords[0]+patchSize[0]),int(new_coords[1]+patchSize[1])))\n",
    "    \n",
    "    new_region_obj.save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_patch_{k:04}.png'))\n",
    "    new_mask_obj.save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_patch_{k:04}.png'))\n",
    "    \n",
    "    '''\n",
    "    Create 4 additional samples per object/patch ... the annotated object will be in each corner\n",
    "    '''\n",
    "    new_region_corner1 = slide.read_region((int(coords[0]*factor), int(coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner1 = mask_obj_WSI.crop((coords[0],coords[1],coords[0]+patchSize[0],coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner1.save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_patch_{k:04}_c1.png'))\n",
    "    new_mask_corner1.save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_patch_{k:04}_c1.png'))\n",
    "\n",
    "    corner2_coords = (coords[2] - patchSize[0], coords[1])\n",
    "    new_region_corner2 = slide.read_region((int(corner2_coords[0]*factor), int(corner2_coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner2 = mask_obj_WSI.crop((corner2_coords[0],corner2_coords[1],corner2_coords[0]+patchSize[0],corner2_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner2.save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_patch_{k:04}_c2.png'))\n",
    "    new_mask_corner2.save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_patch_{k:04}_c2.png'))\n",
    "\n",
    "    corner3_coords = (coords[2] - patchSize[0], coords[3] - patchSize[1])\n",
    "    new_region_corner3 = slide.read_region((int(corner3_coords[0]*factor), int(corner3_coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner3 = mask_obj_WSI.crop((corner3_coords[0],corner3_coords[1],corner3_coords[0]+patchSize[0],corner3_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner3.save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_patch_{k:04}_c3.png'))\n",
    "    new_mask_corner3.save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_patch_{k:04}_c3.png'))\n",
    "\n",
    "    corner4_coords = (coords[0], coords[3] - patchSize[1])\n",
    "    new_region_corner4 = slide.read_region((int(corner4_coords[0]*factor), int(corner4_coords[1]*factor)), SLIDE_DIM_LVL, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner4 = mask_obj_WSI.crop((corner4_coords[0], corner4_coords[1], corner4_coords[0]+patchSize[0],corner4_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner4.save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_patch_{k:04}_c4.png'))\n",
    "    new_mask_corner4.save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_patch_{k:04}_c4.png'))\n",
    "\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg_mask = np.zeros((PATCH_SIZE, PATCH_SIZE))\n",
    "# background_patch = []\n",
    "# for coords_bbox, size_bbox in zip(coords_region, size):\n",
    "#     mask_ROI_WSI = mask_ROI.crop((coords_bbox[0],coords_bbox[1],coords_bbox[0]+size_bbox[0],coords_bbox[1]+size_bbox[1]))\n",
    "#     mask_obj_WSI = mask_obj.crop((coords_bbox[0],coords_bbox[1],coords_bbox[0]+size_bbox[0],coords_bbox[1]+size_bbox[1]))\n",
    "#     region = slide.read_region((int(coords_bbox[0]*factor), int(coords_bbox[1]*factor)), SLIDE_DIM_LVL, (size_bbox[0], size_bbox[1]))\n",
    "\n",
    "#     mask_ROI_WSI = (np.array(mask_ROI_WSI)>0).astype(\"uint8\")\n",
    "#     mask_obj_WSI = (np.array(mask_obj_WSI)>0).astype(\"uint8\")\n",
    "\n",
    "#     patch_ROI = create_image_patches(mask_ROI_WSI, PATCH_SIZE, PATCH_SIZE)\n",
    "#     patch_obj = create_image_patches(mask_obj_WSI, PATCH_SIZE, PATCH_SIZE)\n",
    "#     patch_region = create_image_patches(np.array(region), PATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "#     save_obj = []\n",
    "#     for i in tqdm(range(len(patch_ROI))):\n",
    "#         pixelSumROI = np.sum(patch_ROI[i])\n",
    "#         if pixelSumROI == PATCH_SIZE*PATCH_SIZE:\n",
    "#             pixelSumObj = np.sum(patch_obj[i])\n",
    "#             if pixelSumObj == 0:\n",
    "#                 if patch_region[i][:,:,0:3].std() > 30.0: # get only background with few pixels of glass.\n",
    "#                     background_patch.append(patch_region[i])\n",
    "#                     Image.fromarray(patch_region[i]).save(os.path.join(save_path,f'patches/wsi{SLIDE_ID}_bg_{i:04}.png'))\n",
    "#                     Image.fromarray(bg_mask).convert('L').save(os.path.join(save_path,f'masks/wsi{SLIDE_ID}_bg_{i:04}.png'))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wsi_names = [x.split('/')[-1].split('.ndpi')[0] for x in slides]\n",
    "\n",
    "total_pos = 0\n",
    "total_neg = 0\n",
    "total_patches = 0\n",
    "\n",
    "for name in wsi_names[:SLIDE_ID+1]:\n",
    "    patches_paths = sorted(glob.glob(os.path.join(main_path, f\"{TASK}/{PATCH_SIZE}/{name}/patches/*\")))\n",
    "    nb_total, nb_neg, nb_pos = count_patches(patches_paths)\n",
    "    print(name)\n",
    "    print(f'Number of positive patches (plaques) : {nb_pos}')\n",
    "    print(f'Number of negative patches (backgrounds) : {nb_neg}')\n",
    "    print('\\n')\n",
    "    total_pos += nb_pos\n",
    "    total_neg += nb_neg\n",
    "    total_patches += nb_total\n",
    "    \n",
    "print(f'Total number of positive patches (plaques) : {total_pos}')\n",
    "print(f'Total number of negative patches (backgrounds) : {total_neg}')\n",
    "print(f'Total number of images : {total_patches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZATION_TYPE = 'macenko'\n",
    "reference_path = os.path.join(main_path, f\"references/norm_reference_512x512.png\")\n",
    "wsi_paths = sorted(glob.glob(os.path.join(main_path, f'{TASK}/{PATCH_SIZE}/*')))\n",
    "\n",
    "wsi_path = wsi_paths[SLIDE_ID]\n",
    "wsi_name = wsi_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Preprocessing record {wsi_name}')\n",
    "\n",
    "print(f'    Creating folders')     \n",
    "if not os.path.isdir(os.path.join(wsi_path, f'images_{NORMALIZATION_TYPE}')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'images_{NORMALIZATION_TYPE}'))\n",
    "    \n",
    "if not os.path.isdir(os.path.join(wsi_path, f'annotation_masks')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'annotation_masks'))\n",
    "    \n",
    "if not os.path.isdir(os.path.join(wsi_path, 'tissue_masks')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'tissue_masks'))\n",
    "    \n",
    "if not os.path.isdir(os.path.join(wsi_path, 'pickles')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'pickles'))\n",
    "    \n",
    "\n",
    "raw_patches = glob.glob(os.path.join(wsi_path, 'patches/*.png'))\n",
    "raw_masks = glob.glob(os.path.join(wsi_path, 'masks/*.png'))\n",
    "raw_patches.sort()\n",
    "raw_masks.sort()\n",
    "\n",
    "print('    Normalizing patches')\n",
    "target = np.array(Image.open(reference_path))\n",
    "for patch in tqdm(raw_patches):\n",
    "    raw_array = np.array(Image.open(patch))[:, :, :3]\n",
    "    norm_array = normalize_image(raw_array, target, NORMALIZATION_TYPE, True)\n",
    "    norm_image = Image.fromarray(norm_array)\n",
    "    norm_image.save(os.path.join(wsi_path, f'images_{NORMALIZATION_TYPE}', patch.split('/')[-1]))\n",
    "\n",
    "print('    Generating annotation masks')  \n",
    "images_macenko = glob.glob(os.path.join(wsi_path, f'images_{NORMALIZATION_TYPE}', '*.png'))\n",
    "images_macenko.sort()\n",
    "\n",
    "for image in tqdm(images_macenko):\n",
    "    patch = np.array(Image.open(image))[:, :, :3]\n",
    "    mask = np.array(Image.open(os.path.join(wsi_path, 'masks', image.split('/')[-1])))\n",
    "    new_mask = mask/255\n",
    "    img = Image.fromarray(new_mask).convert('L')\n",
    "    img.save(os.path.join(wsi_path, 'annotation_masks', image.split('/')[-1]))\n",
    "\n",
    "print('    Generating tissue masks')  \n",
    "tissue_detector = GaussianTissueMask(downsampling_factor=2, sigma=5)\n",
    "for image in tqdm(images_macenko):\n",
    "    patch = np.array(Image.open(image))[:, :, :3]\n",
    "    tissue_mask = tissue_detector.process(patch)\n",
    "    img = Image.fromarray(tissue_mask)\n",
    "    img.save(os.path.join(wsi_path, 'tissue_masks', image.split('/')[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob.glob(os.path.join(wsi_path, f'images_{NORMALIZATION_TYPE}', '*.png')))\n",
    "\n",
    "df_image_level_annotations = pd.DataFrame()\n",
    "df_image_level_annotations['name'] = [x.split('/')[-1].split('.')[0] for x in images]\n",
    "df_image_level_annotations['benign'] = np.where(df_image_level_annotations['name'].str.contains('bg_'), 1, 0)\n",
    "df_image_level_annotations['plaque'] = np.where(df_image_level_annotations['name'].str.contains('patch_'), 1, 0)\n",
    "df_image_level_annotations = df_image_level_annotations.set_index('name')\n",
    "df_image_level_annotations.to_pickle(os.path.join(wsi_path, 'pickles', 'image_level_annotations.pickle'))\n",
    "\n",
    "df_images = pd.DataFrame()\n",
    "df_images['name'] = [x.split('/')[-1].split('.')[0] for x in images]\n",
    "df_images['image_path'] = images\n",
    "df_images = df_images.set_index('name')\n",
    "df_images.to_pickle(os.path.join(wsi_path, 'pickles', 'images.pickle'))\n",
    "\n",
    "df_annotation_mask = df_images.copy()\n",
    "df_annotation_mask.rename(columns={'image_path': 'annotation_mask_path'}, inplace=True)\n",
    "df_annotation_mask = df_annotation_mask['annotation_mask_path']\n",
    "df_annotation_mask = df_annotation_mask.str.replace(f'images_{NORMALIZATION_TYPE}', 'annotation_masks')\n",
    "df_annotation_mask.to_pickle(os.path.join(wsi_path, 'pickles', 'annotation_masks.pickle'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, 'partition')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'partition'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, 'partition', 'Test')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'partition', 'Test'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, 'partition', 'Train')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'partition', 'Train'))  \n",
    "    \n",
    "df_partition = pd.DataFrame()\n",
    "df_partition['image_id'] = df_image_level_annotations.index \n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "X_train, X_test = train_test_split(df_partition, test_size=0.1, random_state=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train.to_csv(os.path.join(wsi_path, 'partition', 'Test', 'Train.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(wsi_path, 'partition', 'Test', 'Test.csv'), index=False)\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(wsi_path, 'partition', 'Train', f'Val{i+1}')):\n",
    "        os.mkdir(os.path.join(wsi_path, 'partition', 'Train', f'Val{i+1}'))\n",
    "    \n",
    "    X_t, X_v = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    X_t = X_t.reset_index(drop=True)\n",
    "    X_v = X_v.reset_index(drop=True)\n",
    "\n",
    "    X_t.to_csv(os.path.join(wsi_path, 'partition', 'Train', f'Val{i+1}', 'Train.csv'), index=False)\n",
    "    X_v.to_csv(os.path.join(wsi_path, 'partition', 'Train', f'Val{i+1}', 'Val.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superpixel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(glob.glob(os.path.join(wsi_path, f\"images_{NORMALIZATION_TYPE}/*\")))\n",
    "superpixel_path = os.path.join(wsi_path, 'preprocess', 'superpixels')\n",
    "viz_path = os.path.join(wsi_path, 'preprocess', 'superpixel_viz')\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, 'preprocess')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'preprocess'))\n",
    "if not os.path.isdir(viz_path):\n",
    "    os.mkdir(viz_path)\n",
    "if not os.path.isdir(superpixel_path):\n",
    "    os.mkdir(superpixel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in tqdm(image_paths):\n",
    "    image_name = image_path.split('/')[-1].split('.')[0]\n",
    "    image = np.array(Image.open(image_path))\n",
    "    mask = np.array(Image.open(image_path.replace(f\"images_{NORMALIZATION_TYPE}\",  \"masks\")))\n",
    "\n",
    "    # fig, ax = plt.subplots(5, 2, figsize=(10, 20))\n",
    "    # ax = np.ravel(ax)\n",
    "\n",
    "    # # Image and ground truth\n",
    "    # ax[0].imshow(image)\n",
    "    # ax[0].set_title(f'Normalized image ({NORMALIZATION_TYPE})')\n",
    "    # ax[1].imshow(mask)\n",
    "    # ax[1].set_title('Ground truth annotation (Lev)')\n",
    "\n",
    "    #  Segmentation\n",
    "    # s0 = morphological_chan_vese(image[:, :, 0], iterations=10, smoothing=1)\n",
    "    # s1 = morphological_chan_vese(image[:, :, 1], iterations=10, smoothing=1)\n",
    "    # s2 = morphological_chan_vese(image[:, :, 2], iterations=10, smoothing=1)\n",
    "    # s = s0+s1+s2\n",
    "    # arr = np.where(s==0, 1, 0)\n",
    "    arr = morphological_chan_vese(image[:, :, 0], iterations=10, smoothing=1)\n",
    "    # ax[2].imshow(arr)\n",
    "    # ax[2].set_title('Segmentation')\n",
    "    value, count = np.unique(arr, return_counts=True)\n",
    "    if count[0] < count[1]:\n",
    "        # print('Segmentation : swapping 0s and 1s')\n",
    "        arr = np.where((arr==0)|(arr==1), arr^1, arr)\n",
    "    \n",
    "    # Padding\n",
    "    arr = np.pad(arr, 10, 'constant', constant_values=0)\n",
    "    # ax[3].imshow(arr)\n",
    "    # ax[3].set_title('Padding')\n",
    "\n",
    "    # Binary closing\n",
    "    arr = ndimage.binary_closing(arr, iterations=2)\n",
    "    # ax[4].imshow(arr)\n",
    "    # ax[4].set_title('Binary closing')\n",
    "\n",
    "    # Area cleaning 1 \n",
    "    arr = morphology.remove_small_objects(arr, min_size=2000)\n",
    "    # ax[5].imshow(arr)\n",
    "    # ax[5].set_title('Area cleaning (small objects)')\n",
    "\n",
    "    # Area cleaning 2\n",
    "    arr = morphology.remove_small_holes(arr, area_threshold=600)\n",
    "    # ax[6].imshow(arr)\n",
    "    # ax[6].set_title('Area cleaning (small holes)')\n",
    "\n",
    "    # Labelling\n",
    "    superpixel = label(arr)[0]\n",
    "    # ax[7].imshow(superpixel)\n",
    "    # ax[7].set_title('Superpixel')\n",
    "\n",
    "    values, areas, solidity, eccentricity = get_properties(superpixel)\n",
    "    if np.argmax(areas) != 0:\n",
    "        print(\"Labelling : reindexing background\")\n",
    "        superpixel = np.where(superpixel==0, 10000, superpixel)\n",
    "        superpixel = np.where(superpixel==np.argmax(areas), 0, superpixel)\n",
    "        superpixel = np.where(superpixel==10000, np.argmax(areas), superpixel)\n",
    "\n",
    "\n",
    "    # Solidity cleaning\n",
    "    values, areas, solidity, eccentricity = get_properties(superpixel)\n",
    "\n",
    "    for elem in values[solidity < 0.33]:\n",
    "        superpixel = np.where(superpixel==elem, np.argmax(areas), superpixel)\n",
    "        \n",
    "    for index, elem in enumerate(np.unique(superpixel)):\n",
    "        superpixel = np.where(superpixel==elem, index, superpixel)\n",
    "        \n",
    "    superpixel = superpixel[10:-10, 10:-10] + 1\n",
    "    save_superpixel_map(superpixel, os.path.join(superpixel_path, image_name + '.h5'))\n",
    "    \n",
    "    # ax[8].imshow(superpixel) \n",
    "    # ax[8].set_title('Solidity cleaning')\n",
    "\n",
    "    # ax[9].imshow(mark_boundaries(image, superpixel, color=(0, 255, 0)))\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(viz_path, f\"{image_path.split('/')[-1].split('.')[0]}_1.png\"), dpi=300)\n",
    "    # plt.close()\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    # ax.imshow(mark_boundaries(mark_boundaries(image, mask, color=(0, 0, 255)), superpixel, color=(0, 255, 0)))\n",
    "\n",
    "    # green_patch = mpatches.Patch(color='green', label='MorphChanVese Superpixel')\n",
    "    # blue_patch = mpatches.Patch(color='blue', label='Lev Annotation')\n",
    "    # plt.legend(bbox_to_anchor=(0.70, 1.1), handles=[green_patch, blue_patch])\n",
    "    # plt.savefig(os.path.join(viz_path, f\"{image_path.split('/')[-1].split('.')[0]}_2.png\"), dpi=300)\n",
    "    # plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AugmentedDeepFeatureExtractor(\n",
    "    architecture='mobilenet_v2',\n",
    "    num_workers=8,\n",
    "    # rotations=[0, 90, 180, 270],\n",
    "    # flips=['n', 'h'],\n",
    "    patch_size=9,\n",
    "    resize_size=224,\n",
    "    batch_size=256\n",
    "    )\n",
    "\n",
    "graph_builder = RAGGraphBuilder(\n",
    "    nr_annotation_classes=3,\n",
    "    annotation_background_class=2,\n",
    "    add_loc_feats=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_paths = sorted(glob.glob(os.path.join(superpixel_path, '*.h5')))\n",
    "image_paths = sorted(image_paths)\n",
    "mask_paths = sorted(glob.glob(os.path.join(wsi_path, 'annotation_masks/*')))\n",
    "assert len(spx_paths) == len(image_paths) == len(mask_paths)\n",
    "\n",
    "# Create preprocessing folders\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/graphs')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/graphs'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/graphs_viz')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/graphs_viz'))\n",
    "    \n",
    "from tqdm import trange\n",
    "\n",
    "for i in tqdm(np.arange(470, 795)):\n",
    "    image_name = spx_paths[i].split('/')[-1].split('.')[0]\n",
    "    spx_path = spx_paths[i]\n",
    "    image = np.array(Image.open(image_paths[i]))\n",
    "    mask = np.array(Image.open(mask_paths[i]))\n",
    "    with h5py.File(spx_path, 'r') as f:\n",
    "        superpixels = f['default_key_0'][:, :]\n",
    "        features = feature_extractor.process(image, superpixels)\n",
    "        graph = graph_builder.process(superpixels, features, mask) # Compute graph\n",
    "        save_graphs(filename=os.path.join(wsi_path, f'preprocess/graphs', image_name + '.bin'), g_list=[graph])\n",
    "        \n",
    "        visualizer = OverlayGraphVisualization()\n",
    "        canvas = visualizer.process(image, graph, instance_map=superpixels) # Create graph visualization\n",
    "        canvas.save(os.path.join(wsi_path, f'preprocess/graphs_viz', image_name + '.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPX_SIZE = 128\n",
    "BLUR_SIZE = 0\n",
    "PSIZE = 3\n",
    "\n",
    "# Create preprocessing folders\n",
    "if not os.path.isdir(os.path.join(wsi_path, 'preprocess')):\n",
    "    os.mkdir(os.path.join(wsi_path, 'preprocess'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}'))\n",
    "    \n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/superpixels')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/superpixels'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs_viz')):\n",
    "    os.mkdir(os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs_viz'))\n",
    "    \n",
    "# Instantiate preprocessing operators \n",
    "spx_extractor = SLICSuperpixelExtractor(\n",
    "    superpixel_size=SPX_SIZE,\n",
    "    blur_kernel_size=BLUR_SIZE,\n",
    "    compactness=20,\n",
    "    downsampling_factor=1\n",
    "    )\n",
    "\n",
    "feature_extractor = AugmentedDeepFeatureExtractor(\n",
    "    architecture='mobilenet_v2',\n",
    "    num_workers=8,\n",
    "    rotations=[0, 90, 180, 270],\n",
    "    flips=['n', 'h'],\n",
    "    patch_size=PSIZE,\n",
    "    resize_size=224,\n",
    "    batch_size=256\n",
    "    )\n",
    "\n",
    "graph_builder = RAGGraphBuilder(\n",
    "    nr_annotation_classes=3,\n",
    "    annotation_background_class=2,\n",
    "    add_loc_feats=False\n",
    "    )\n",
    "\n",
    "# Preprocessing\n",
    "for image_path in tqdm(images_macenko):\n",
    "    image_name = os.path.basename(image_path).split('.')[0]\n",
    "    image = np.array(Image.open(image_path))\n",
    "    mask_path = image_path.replace('images_macenko', 'annotation_masks')\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    \n",
    "    superpixels = spx_extractor.process(image) # Extract superpixels\n",
    "    save_superpixel_map(superpixels, os.path.join(wsi_path, f'preprocess/{nb_preproc}/superpixels', image_name + '.h5'))\n",
    "                        \n",
    "    features = feature_extractor.process(image, superpixels) # Extract features from superpixels\n",
    "\n",
    "    graph = graph_builder.process(superpixels, features, mask) # Compute graph\n",
    "    save_graphs(filename=os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs', image_name + '.bin'), g_list=[graph])\n",
    "\n",
    "    visualizer = OverlayGraphVisualization()\n",
    "    canvas = visualizer.process(image, graph, instance_map=superpixels) # Create graph visualization\n",
    "    canvas.save(os.path.join(wsi_path, f'preprocess/{nb_preproc}/graphs_viz', image_name + '.png'))\n",
    "\n",
    "# Save the parameters into a JSON file  \n",
    "feature_extractor.__dict__.pop('transforms', None)\n",
    "feature_extractor.__dict__.pop('device', None)\n",
    "feature_extractor.__dict__.pop('patch_feature_extractor', None)\n",
    "\n",
    "params = {'spx_extractor': spx_extractor.__dict__,\n",
    "          'feature_extractor':feature_extractor.__dict__,\n",
    "          'graph_builder': graph_builder.__dict__}\n",
    "\n",
    "with open(os.path.join(wsi_path, 'preprocess/{nb_preproc}/parameters.json'), 'w') as fp:\n",
    "    json.dump(params, fp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09b8c83cdd02532630cfadd62ea7f6bf102ec9c25c0b4d7cb59600b0d46096f2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('seggini')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
